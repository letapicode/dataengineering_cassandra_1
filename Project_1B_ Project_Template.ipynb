{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import decimal\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace \n",
      "\n",
      "['/home/workspace/event_data/.ipynb_checkpoints/2018-11-15-events-checkpoint.csv', '/home/workspace/event_data/.ipynb_checkpoints/2018-11-05-events-checkpoint.csv']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The code retrieves a list of file paths from the \"event_data\" directory in the current working directory \n",
    "and prints the current working directory and the first two file paths in the list.\n",
    "\"\"\"\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "\n",
    "print(os.getcwd(), \"\\n\")\n",
    "print(file_path_list[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in full_data_rows_list: \n",
      "2937 \n",
      "\n",
      "The data inside the full_data_rows_list looks like:\n",
      "[['Harmonia', 'Logged In', 'Ryan', 'M', '0', 'Smith', '655.77751', 'free', 'San Jose-Sunnyvale-Santa Clara, CA', 'PUT', 'NextSong', '1.54102E+12', '583', 'Sehr kosmisch', '200', '1.54224E+12', '26'], ['The Prodigy', 'Logged In', 'Ryan', 'M', '1', 'Smith', '260.07465', 'free', 'San Jose-Sunnyvale-Santa Clara, CA', 'PUT', 'NextSong', '1.54102E+12', '583', 'The Big Gundown', '200', '1.54224E+12', '26']]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The code reads data from each file in the file_path_list and \n",
    "appends each row of data to the 'full_data_rows_list' list.\n",
    "\"\"\"\n",
    "\n",
    "full_data_rows_list = [] \n",
    "\n",
    "for f in file_path_list:\n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        #The first row is just the names of the columns, so skip it\n",
    "        next(csvreader)    \n",
    "        for line in csvreader:\n",
    "            full_data_rows_list.append(line) \n",
    "\n",
    "            \n",
    "print(\"Number of rows in full_data_rows_list: \")\n",
    "print(len(full_data_rows_list),\"\\n\")\n",
    "\n",
    "print(\"The data inside the full_data_rows_list looks like:\")\n",
    "print(full_data_rows_list[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In summary, this code creates a CSV file with a specific format, writes a header row to the file, \n",
    "and then writes data rows to the file based on the contents of a list of data rows. \n",
    "The if statement is used to skip any rows that don't contain data in the first column.\n",
    "The 'event_datafile_new.csv' file will be used to insert data into Cassandra tables\n",
    "\"\"\"\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in even_datafile_new file:\n",
      "2532\n"
     ]
    }
   ],
   "source": [
    "# Count the number of lines in a CSV file called \"event_datafile_new.csv\"\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(\"Number of rows in even_datafile_new file:\")\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II.The Apache Cassandra \n",
    "\n",
    "## The <font color=red>event_datafile_new.csv</font> contains the following columns: \n",
    "\n",
    "- 0 ----- artist \n",
    "- 1 ----- firstName of user\n",
    "- 2 ----- gender of user\n",
    "- 3 ----- item number in session\n",
    "- 4 ----- last name of user\n",
    "- 5 ----- length of the song\n",
    "- 6 ----- level (paid or free song)\n",
    "- 7 ----- location of the user\n",
    "- 8 ----- sessionId\n",
    "- 9 ----- song title\n",
    "- 10 ---- userId\n",
    "\n",
    "\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> file:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Cassandra code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The code creates a connection to a Cassandra cluster running on the local machine \n",
    "and prints any exceptions that occur during the connection process.\n",
    "\"\"\"\n",
    "from cassandra.cluster import Cluster\n",
    "try:\n",
    "    cluster = Cluster(['127.0.0.1'])\n",
    "    session = cluster.connect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The code tries to execute a CQL query to create a keyspace named \"project_songs\" with a \n",
    "replication strategy of SimpleStrategy and a replication factor of 1, and if there's an exception, \n",
    "it prints the error message.\n",
    "\"\"\"\n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS project_songs\n",
    "    WITH REPLICATION = \n",
    "    {'class': 'SimpleStrategy', 'replication_factor':1}\"\"\"\n",
    ")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The code attempts to set the keyspace to \"project_songs\" using the set_keyspace method of \n",
    "a session object, and if an exception is raised, it prints the error message to the console.\n",
    "\"\"\"\n",
    "try:\n",
    "    session.set_keyspace('project_songs')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Apache Cassandra you model the database tables on the queries you want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create queries to ask the following of the data\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The PRIMARY KEY is defined as (session_id, item_in_session). In Apache Cassandra, the PRIMARY KEY \n",
    "is used to uniquely identify each row in a table.\n",
    "\n",
    "In this case, the PRIMARY KEY is composed of two columns: session_id and item_in_session. \n",
    "This means that each row in the music_app_history table will be uniquely identified by a \n",
    "combination of these two columns.\n",
    "\n",
    "The decision to use (session_id, item_in_session) as the PRIMARY KEY was based on the \n",
    "requirements of the application. In this case, the application needs to be able \n",
    "to query the 'song_info_by_session' table based on both session_id and item_in_session. By using \n",
    "these two columns as the PRIMARY KEY, the table will be optimized for queries that filter on these columns.\n",
    "\n",
    "It's worth noting that the order of the columns in the PRIMARY KEY is important. In this case, \n",
    "session_id is listed first, which means that rows will be partitioned based on session_id. \n",
    "This can be useful for queries that filter on session_id, as it allows Cassandra to efficiently \n",
    "retrieve all rows with a given session_id. The item_in_session column is listed second, which \n",
    "means that it will be used as a clustering column. Clustering columns determine the order in \n",
    "which rows are stored within a partition, and can be used to sort and filter data within a partition.\n",
    "\"\"\"\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS song_info_by_session \"\n",
    "query = query + \"(session_id int, item_in_session int, artist text, song_title text, song_length decimal, \\\n",
    "                    PRIMARY KEY (session_id,item_in_session))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"   \n",
    "The code reads in data from a CSV file called \"event_datafile_new.csv\", skips the header row, \n",
    "and then iterates through each row of data, inserting specific columns of data into a \n",
    "table called \"song_info_by_session\" in Apache Cassandra.\n",
    "\"\"\"\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) \n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO song_info_by_session (session_id, item_in_session, artist, song_title, song_length)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], decimal.Decimal(line[5])))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five rows from the 'song_info_by_session' table:\n",
      "+--------------------+-----------------------------------+-----------+\n",
      "|       Artist       |                Song               |   Length  |\n",
      "+--------------------+-----------------------------------+-----------+\n",
      "|   Regina Spektor   |  The Calculation (Album Version)  | 191.08526 |\n",
      "|  Octopus Project   | All Of The Champs That Ever Lived | 250.95791 |\n",
      "|   Tegan And Sara   |             So Jealous            | 180.06159 |\n",
      "|     Dragonette     |            Okay Dolores           | 153.39057 |\n",
      "| Lil Wayne / Eminem |           Drop The World          | 229.58975 |\n",
      "+--------------------+-----------------------------------+-----------+ \n",
      "\n",
      "The artist, song title and song's length for session_id 338, and item_in_session 4:\n",
      "+-----------+---------------------------------+----------+\n",
      "|   Artist  |               Song              |  Length  |\n",
      "+-----------+---------------------------------+----------+\n",
      "| Faithless | Music Matters (Mark Knight Dub) | 495.3073 |\n",
      "+-----------+---------------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT artist, song_title, song_length FROM song_info_by_session limit 5\"\n",
    "\n",
    "try: \n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "query_table = PrettyTable(['Artist', 'Song', 'Length'])\n",
    "for row in rows:\n",
    "    query_table.add_row([row.artist, row.song_title, row.song_length])\n",
    "\n",
    "print(\"Five rows from the 'song_info_by_session' table:\")\n",
    "print(query_table, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "query2 = \"SELECT artist, song_title, song_length FROM song_info_by_session WHERE session_id=338 AND item_in_session=4\"\n",
    "try: \n",
    "    rows2 = session.execute(query2)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if rows2:\n",
    "    query_table.clear_rows()\n",
    "    for row in rows2:\n",
    "        query_table.add_row([row.artist, row.song_title, row.song_length])\n",
    "        \n",
    "    print(\"The artist, song title and song's length for session_id 338, and item_in_session 4:\")\n",
    "    print(query_table)    \n",
    "else:\n",
    "    print(\"The record for session_id 338, item_in_session 4 is missing on the 'song_info_by_session' table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create queries to ask the following of the data\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this case, the PRIMARY KEY is composed of three columns: user_id, session_id, and item_in_session.\n",
    "This means that data will be partitioned based on the values in these columns. The user_id, and session_id is the\n",
    "the partition key, meaning that data will be grouped together based on the value in these columns. \n",
    "Within each partition, data will be sorted based on the values in the item_in_session column.\n",
    "\n",
    "By using user_id and session_id as the partition key, all of a user's listening history will be stored \n",
    "together on a single node, making queries for that user's history fast and efficient. \n",
    "The item_in_session column is included in the PRIMARY KEY to ensure that  data is sorted correctly\n",
    "within each partition.\n",
    "\n",
    "The Partition Key is responsible for data distribution across the nodes.\n",
    "The Clustering Key is responsible for data sorting within the partition.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS artist_user_info_by_id \"\n",
    "query = query + \"(user_id int, session_id int, item_in_session int, artist text, song_title text, first_name text, \\\n",
    "                    last_name text, PRIMARY KEY ((user_id, session_id), item_in_session))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code reads data from a CSV file called \"event_datafile_new.csv\" and inserts the \n",
    "data into a table called \"artist_user_info_by_id\" in Apache Cassandra using the \n",
    "execute method of a session object.\n",
    "\"\"\"\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    # skip header\n",
    "    next(csvreader) \n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO artist_user_info_by_id (user_id, session_id, item_in_session, artist, song_title, \\\n",
    "                                                        first_name, last_name)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five rows from the 'artist_user_info_by_id' table:\n",
      "+--------------------------------------+-------------------------------------------+------------+-----------+\n",
      "|                Artist                |                    Song                   | First Name | Last Name |\n",
      "+--------------------------------------+-------------------------------------------+------------+-----------+\n",
      "|             1 Mile North             |                Black Lines                |    Ryan    |   Smith   |\n",
      "|   USS (Ubiquitous Synergy Seeker)    |             Man Makes The Zoo             |    Ryan    |   Smith   |\n",
      "| EsmÃÂ©e Denters / Justin Timberlake | Love Dealer (Featuring Justin Timberlake) |    Ryan    |   Smith   |\n",
      "|                Train                 |              Hey_ Soul Sister             |    Ryan    |   Smith   |\n",
      "|   The Pussycat Dolls / Snoop Dogg    |                 Bottle Pop                |    Ryan    |   Smith   |\n",
      "+--------------------------------------+-------------------------------------------+------------+-----------+ \n",
      "\n",
      "The name of artist, song and user (first & last name) for userid = 10, and sessionid = 182:\n",
      "+-------------------+------------------------------------------------------+------------+-----------+\n",
      "|       Artist      |                         Song                         | First Name | Last Name |\n",
      "+-------------------+------------------------------------------------------+------------+-----------+\n",
      "|  Down To The Bone |                  Keep On Keepin' On                  |   Sylvie   |    Cruz   |\n",
      "|    Three Drives   |                     Greece 2000                      |   Sylvie   |    Cruz   |\n",
      "| Sebastien Tellier |                      Kilometer                       |   Sylvie   |    Cruz   |\n",
      "|   Lonnie Gordon   | Catch You Baby (Steve Pitron & Max Sanna Radio Edit) |   Sylvie   |    Cruz   |\n",
      "+-------------------+------------------------------------------------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT artist, song_title, first_name, last_name FROM artist_user_info_by_id limit 5\"\n",
    "\n",
    "try: \n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "query_table = PrettyTable(['Artist', 'Song', 'First Name', 'Last Name'])\n",
    "for row in rows:\n",
    "    query_table.add_row([row.artist, row.song_title, row.first_name, row.last_name])\n",
    "\n",
    "print(\"Five rows from the 'artist_user_info_by_id' table:\")\n",
    "print(query_table, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "query2 = \"SELECT artist, song_title, first_name, last_name FROM artist_user_info_by_id WHERE \\\n",
    "                user_id=10 AND session_id=182\"\n",
    "try: \n",
    "    rows2 = session.execute(query2)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if rows2:\n",
    "    query_table.clear_rows()\n",
    "    for row in rows2:\n",
    "        query_table.add_row([row.artist, row.song_title, row.first_name, row.last_name])\n",
    "        \n",
    "    print(\"The name of artist, song and user (first & last name) for userid = 10, and sessionid = 182:\")\n",
    "    print(query_table)    \n",
    "else:\n",
    "    print(\"The record for user_id 10 and session_id 182 is missing on the 'artist_user_info_by_id' table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create queries to ask the following of the data\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In Cassandra, the primary key is used to determine the partition key and the clustering columns. \n",
    "The partition key is used to distribute the data across the cluster, while the clustering columns\n",
    "are used to sort the data within each partition.\n",
    "\n",
    "In our example, we have chosen song_title as our partition key and user_id as our clustering column. \n",
    "This means that all data for a particular song will be stored together in the same partition, and \n",
    "within each partition, the data will be sorted by user ID.\n",
    "\n",
    "We chose song_title as our partition key because we want to be able to query the data based \n",
    "on the song title. We chose user_id as our clustering column because we want to be able to sort \n",
    "the data within each partition by user ID.\n",
    "\n",
    "If you don't involve the user_id column in this case, you won't be able to sort the results by user. \n",
    "The query would still return every user who listened to the song \"All Hands Against His Own\", but the \n",
    "results would be in an arbitrary order.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS username_by_songtitle \"\n",
    "query = query + \"(song_title text, user_id int, first_name text, last_name text, PRIMARY KEY (song_title, user_id))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code reads data from a CSV file named \"event_datafile_new.csv\" and inserts the \n",
    "data into a table called \"username_by_songtitle\" in Apache Cassandra.\n",
    "\"\"\"\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO username_by_songtitle (song_title, user_id, first_name, last_name)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s)\"\n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five rows from the 'username_by_songtitle' table:\n",
      "+-------------------------------------+------------+-----------+\n",
      "|                 Song                | First Name | Last Name |\n",
      "+-------------------------------------+------------+-----------+\n",
      "|  Too Tough (1994 Digital Remaster)  |   Aleena   |   Kirby   |\n",
      "| Rio De Janeiro Blue (Album Version) |   Chloe    |   Cuevas  |\n",
      "|             Misfit Love             |   Jayden   |   Graves  |\n",
      "|           Hey_ Soul Sister          |    Ryan    |   Smith   |\n",
      "|           Hey_ Soul Sister          |   Carlos   |   Carter  |\n",
      "+-------------------------------------+------------+-----------+ \n",
      "\n",
      "Users who listened to the song 'All Hands Against His Own'\n",
      "+---------------------------+------------+-----------+\n",
      "|            Song           | First Name | Last Name |\n",
      "+---------------------------+------------+-----------+\n",
      "| All Hands Against His Own |   Tegan    |   Levine  |\n",
      "| All Hands Against His Own |    Sara    |  Johnson  |\n",
      "+---------------------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT song_title, first_name, last_name FROM username_by_songtitle limit 5\"\n",
    "\n",
    "try: \n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "query_table = PrettyTable(['Song', 'First Name', 'Last Name'])\n",
    "for row in rows:\n",
    "    query_table.add_row([row.song_title, row.first_name, row.last_name])\n",
    "\n",
    "print(\"Five rows from the 'username_by_songtitle' table:\")\n",
    "print(query_table, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "query2 = \"SELECT song_title, first_name, last_name FROM username_by_songtitle WHERE song_title='All Hands Against His Own'\"\n",
    "try: \n",
    "    rows2 = session.execute(query2)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if rows2:\n",
    "    query_table.clear_rows()\n",
    "    for row in rows2:\n",
    "        query_table.add_row([row.song_title, row.first_name, row.last_name])\n",
    "        \n",
    "    print(\"Users who listened to the song 'All Hands Against His Own'\")\n",
    "    print(query_table)    \n",
    "else:\n",
    "    print(\"The records for the users whoe listened to the song 'All Hands Against His Own' are missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"drop table song_info_by_session\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "query = \"drop table artist_user_info_by_id\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "query = \"drop table username_by_songtitle\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
